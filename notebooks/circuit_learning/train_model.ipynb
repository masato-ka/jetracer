{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "#Adjustment for circuit size and FPS.\n",
    "NUM_TIMESTEPS = 100\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 1)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, we'll create the optimizer that we'll use to train the neural network.  We'll use the ``Adam`` optimizer with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Creating label that learning circuit curvarture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "NEW_CIRCUIT_LOG = 'reformat_circuit_log'\n",
    "CIRCUIT_LOG = 'circuit_log'\n",
    "\n",
    "os.makedirs(NEW_CIRCUIT_LOG, exist_ok=True)\n",
    "image_paths = sorted(glob.glob(os.path.join(CIRCUIT_LOG, '*.jpg')))\n",
    "num_timesteps = NUM_TIMESTEPS\n",
    "gain = np.exp(-15e-2 * np.linspace(0.0, num_timesteps, num_timesteps))\n",
    "\n",
    "for idx in range(len(image_paths)-num_timesteps):\n",
    "\n",
    "    target = np.zeros(num_timesteps)\n",
    "    label = None\n",
    "    for i in range(num_timesteps):\n",
    "        path = os.path.splitext(os.path.basename(image_paths[idx + i]))[0]\n",
    "        x = float(int(path.split('_')[1]) - 50) / 50.0\n",
    "        target[i] = x if abs(x) > 0.20 else 0\n",
    "    label = np.sum(gain * np.abs(target) / np.sum(gain))\n",
    "    if label is None:\n",
    "        print(\"[ERROR] Break! failed create label on \" + file_name)\n",
    "        break\n",
    "    str_label = str(label).replace('.','-')\n",
    "    prifix_filename = os.path.basename(image_paths[idx]).split('_')[0]\n",
    "    rename_file = prifix_filename + '_' + str_label + '.jpg'\n",
    "    shutil.copy(image_paths[idx], os.path.join(NEW_CIRCUIT_LOG, rename_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, execute the following cell to train the neural network for the number of epochs specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import os\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "class CircuitDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, directory, num_timesteps, gamma=5e-3, transform=None):\n",
    "        self.directory = directory\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(self.directory, '*.jpg')))\n",
    "        self.transform = transform\n",
    "        self.num_timesteps = num_timesteps\n",
    "        #self.gain = torch.exp(-3e-2*torch.linspace(0.0, num_timesteps, num_timesteps))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) - self.num_timesteps\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = PIL.Image.fromarray(image)\n",
    "        width = image.width\n",
    "        height = image.height\n",
    "\n",
    "        slottle = float(os.path.basename(image_path).split('_')[1].replace('-','.'))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(slottle).float()\n",
    "        # target = torch.zeros(self.num_timesteps)\n",
    "        # for i in range(self.num_timesteps):\n",
    "        #     path = os.path.splitext(os.path.basename(self.image_paths[idx + i]))[0]\n",
    "        #     x = float(int(path.split('_')[1]) - 50) / 50.0\n",
    "        #     target[i] = x\n",
    "        \n",
    "        # return image, torch.sum(self.gain * torch.abs(target) / torch.sum(self.gain), dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CircuitDataset(NEW_CIRCUIT_LOG, NUM_TIMESTEPS, gamma=1e-2, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for image, target in iter(loader):\n",
    "        \n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(image)\n",
    "        \n",
    "        loss = F.mse_loss(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += float(loss)\n",
    "        \n",
    "    epoch_loss /= len(loader)\n",
    "    \n",
    "    print('%d: %f' % (epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, we save the model for use in the live demo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'circuit_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "image = PIL.Image.open('./circuit_log/000000000111_052.jpg')\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "\n",
    "def preprocess(image):\n",
    "    device = torch.device('cuda')\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "\n",
    "image = preprocess(np.asarray(image))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "x = model(image)\n",
    "x = x.detach().cpu().float()\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}